server:
  port: ${SERVER_PORT:8083}

# MongoDB Configuration
spring:
  data:
    mongodb:
      uri: ${MONGODB_URI}
      auto-index-creation: true

  # Kafka Configuration
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS}
    
    # Security Configuration (for Confluent Cloud)
    properties:
      security.protocol: SASL_SSL
      sasl.mechanism: PLAIN
      sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username="${KAFKA_API_KEY}" password="${KAFKA_API_SECRET}";
      ssl.endpoint.identification.algorithm: https
    
    # Consumer Configuration
    consumer:
      group-id: cloudinsight-anomaly-group
      auto-offset-reset: earliest
      enable-auto-commit: false
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring.json.trusted.packages: "com.cloudinsight.events,com.cloudinsight.anomalyservicerw.events"
        spring.json.value.default.type: com.cloudinsight.anomalyservicerw.events.ServiceCostComputedEvent
      max-poll-records: 50
      fetch-min-size: 1024
      fetch-max-wait: 500ms
    
    # Producer Configuration (for publishing anomaly alerts)
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      acks: all
      retries: 3
      compression-type: snappy
      properties:
        enable.idempotence: true
    
    # Listener Configuration
    listener:
      ack-mode: manual
      concurrency: 3

# Anomaly Detection Configuration
anomaly:
  kafka:
    topic-cost: service.cost.computed
    topic-anomaly: anomaly.detected
  
  model:
    base-path: ${MODEL_BASE_PATH:./models}
    default-filename: isolation_forest.model
    trees: 100
    sample-size: 256
    threshold: 0.75
    window-days: 90
    retrain-days: 7
    min-training-samples: 30
  
  storage:
    serialize-format: java-serialization
  
  executor:
    thread-pool-size: 4
  
  validation:
    min-samples: 30
    max-zero-ratio: 0.7
    strict-validation: false

# Management & Health
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: always

# Eureka Client
eureka:
  client:
    serviceUrl:
      defaultZone: ${SPRING_EUREKA_CLIENT_SERVICEURL_DEFAULTZONE}
  instance:
    prefer-ip-address: ${EUREKA_CLIENT_INSTANCE_PREFER_IP_ADDRESS:true}

# Logging
logging:
  level:
    root: INFO
    com.cloudinsight.anomalyservicerw: DEBUG
    org.springframework.kafka: DEBUG
    org.apache.kafka: INFO

---
# Development Profile
spring:
  config:
    activate:
      on-profile: dev

logging:
  level:
    com.cloudinsight.anomalyservicerw: DEBUG
    org.springframework.kafka: DEBUG
    org.apache.kafka: DEBUG

---
# Production Profile
spring:
  config:
    activate:
      on-profile: prod

logging:
  level:
    root: WARN
    com.cloudinsight.anomalyservicerw: INFO
    org.springframework.kafka: INFO
